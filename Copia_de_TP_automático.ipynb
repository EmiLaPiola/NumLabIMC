{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EmiLaPiola/NumLabIMC/blob/main/Copia_de_TP_autom%C3%A1tico.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "D5fMYLkWoUlM"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import matplotlib.pyplot as plt\n",
        "import tree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, average_precision_score, roc_auc_score\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "df = pd.read_csv('data.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejercicio 1 — Separación de datos\n",
        "\n",
        "> *Evaluar y justificar cómo separarán sus datos para desarrollo y para evaluación. No usar `train_test_split` de sklearn.*"
      ],
      "metadata": {
        "id": "5bCAhm_npbMh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Antes de separar los 500 datos en conjuntos de desarrollo y test, analizamos la variable `target` para contar cuántas instancias son positivas y cuántas negativas. La idea es darnos cuenta si las clases estan balanceadas o no . En el segundo caso , deberiamos hacer una división estratificada.\n"
      ],
      "metadata": {
        "id": "Z7Yy2-VnraDs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['target'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "eARoHw6Br9Rp",
        "outputId": "81da0608-8af5-435b-8a3f-1a1c0a2d3df7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "target\n",
              "0    353\n",
              "1    147\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>target</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>353</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>147</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El data set esta muy desbalanceado, hay mucha mas instancias con mal pronostico ( target 0 ) y solo un 29.4% de los datos tienen buen pronostico (target 1). Así que para separar nuestros datos no lo haremos al azar. La separacion sera estratificada para que la proporicon de la clase minoritaria ( buen pronostico) se preserve en ambos conjuntos. Utilizaremos 80 % de los datos para train y 20 % para control."
      ],
      "metadata": {
        "id": "xjXk6xUMsMxo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Haciendo la partición en 80-20, tenemos 400 instancias en el conjunto de desarrollo y 100 en el de control. Para garantizar la estratificación, seleccionamos aproximadamente el 20% de los casos positivos y el 20% de los negativos para formar el conjunto de control. De esta manera , ambos conjuntos mantienen la proporción original de clases."
      ],
      "metadata": {
        "id": "OhK6YEBS64dg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inicialmente entonces creamos dos data sets distintos. Uno destinado para el desarrolo y otro para la evaluación."
      ],
      "metadata": {
        "id": "q3aejzrKvTbu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# separamos positivos (buen pronostico) y negativos (mal pronsotico)\n",
        "positivos = df[df['target'] == True]\n",
        "negativos = df[df['target'] == False]\n",
        "\n",
        "# seleccionamos al azar el 20% para control\n",
        "control_positivos = positivos.sample(frac=0.2, random_state=42)\n",
        "control_negativos = negativos.sample(frac=0.2, random_state=42)\n",
        "\n",
        "# concatenamos el set de control\n",
        "NO_TOCAR_set = pd.concat([control_positivos, control_negativos])   # NO TOCAR\n",
        "\n",
        "# El resto de los datos queda para desarrollo\n",
        "desarrollo_set = df.drop(NO_TOCAR_set.index)\n",
        "\n",
        "print(f\"Desarrollo: {len(desarrollo_set)} instancias\")\n",
        "print(f\"Control: {len(NO_TOCAR_set)} instancias\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOZg1sYjs6ix",
        "outputId": "8b84313d-b288-4f73-8d9f-4eff13dfce4c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Desarrollo: 400 instancias\n",
            "Control: 100 instancias\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejercicio 2 — Entrenamiento\n",
        "\n",
        "> a) *Entrenar un árbol de decisión con altura máxima 3 y el resto de los hiperparámetros en default. Estimar la performance del modelo utilizando K-fold cross validation con K=5, con las métricas Accuracy, Area Under the Precision-Recall Curve (AUPRC), y Area Under the Receiver Operating Characteristic Curve (AUCROC).*"
      ],
      "metadata": {
        "id": "RHIPrs1_wLHG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para hacer CV con 5 folds, primero vamos a hacer una division estratificada de estos . Como ya dijimos antes, tenemos muy pocos positivos y muchos negativos, las clases estan muy desbalanceadas, por ende, si hicieramos la division de Kfold-CV al azar, podríamos obtener un modelo entrenado con una sola clase y métricas engañosas ... no es la idea.\n",
        "Asi que vamos a usar K-fold-CV estratificado para mantener la proporcion de clases en cada fold."
      ],
      "metadata": {
        "id": "m1eMlXDAuzVk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# hacemos 5 folds estratificados para que haya las mismas proprciones de clases minoritarias y mayoritarias en todos los folds.\n",
        "\n",
        "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state = 22)\n",
        "\n",
        "# separamos de nuestro data set la columna \"target\"\n",
        "\n",
        "desarrollo_set = desarrollo_set.reset_index(drop=True)\n",
        "x_desarrollo = desarrollo_set.drop('target', axis=1)\n",
        "y_desarrollo = desarrollo_set['target']\n",
        "\n",
        "\n",
        "# inicializamos nuestras listas para guadar las metricas\n",
        "\n",
        "vector_accuracy_train= []       # accuracy en training en cada fold\n",
        "vector_accuracy_validacion= []  # lo mismo en validacion\n",
        "\n",
        "vector_auprc_train  = []        # AUPRC en training en cada fold\n",
        "vector_auprc_validacion = []    # lo mismo pero en val\n",
        "\n",
        "vector_auroc_train = []         # AUC ROC en training en cada fold\n",
        "vector_auroc_validacion=[]      # lo mismo pero en val\n",
        "\n",
        "\n",
        "# creamos un array para guardar las predicciones\n",
        "y_pred = np.empty(y_desarrollo.shape)\n",
        "y_pred.fill(np.nan)\n",
        "\n",
        "# lo mismo pero para guardar la probabilidad predicha de pertenecer a la clase positiva\n",
        "# esto lo vamos a usar para calcular AUC-ROC y AUPRC\n",
        "y_pred_prob = np.empty(y_desarrollo.shape)\n",
        "y_pred_prob.fill(np.nan)\n"
      ],
      "metadata": {
        "id": "BCmauosmz23z"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generamos para cada fold una predicción\n",
        "for train_index, test_index in folds.split(x_desarrollo,y_desarrollo):\n",
        "\n",
        "        #saco el fold que no uso para entrenar\n",
        "        kf_X_train, kf_X_test = x_desarrollo.iloc[train_index], x_desarrollo.iloc[test_index]\n",
        "        kf_y_train, kf_y_test = y_desarrollo.iloc[train_index], y_desarrollo.iloc[test_index]\n",
        "\n",
        "        # arbol de altura 3 con los datos de train\n",
        "        arbol = DecisionTreeClassifier(max_depth=3)\n",
        "        arbol.fit(kf_X_train, kf_y_train)\n",
        "        y_pred_prob[test_index] = arbol.predict_proba(kf_X_test)[:, 1] # la prob pred de clase positiva para val de ese fold\n",
        "\n",
        "        # hacemos las predicciones\n",
        "        predictions = arbol.predict(kf_X_test)\n",
        "        y_pred[test_index] = predictions\n",
        "\n",
        "        # accuracy\n",
        "        vector_accuracy_validacion.append(accuracy_score(kf_y_test, predictions))\n",
        "        vector_accuracy_train.append(accuracy_score(kf_y_train, arbol.predict(kf_X_train)))\n",
        "\n",
        "\n",
        "        # AUPRC\n",
        "        auprc = average_precision_score(kf_y_test, arbol.predict_proba(kf_X_test)[:, 1])\n",
        "        vector_auprc_validacion.append(auprc)\n",
        "        vector_auprc_train.append(average_precision_score(kf_y_train, arbol.predict_proba(kf_X_train)[:, 1]))\n",
        "\n",
        "        # AUROC\n",
        "        auc_roc = roc_auc_score(kf_y_test, arbol.predict_proba(kf_X_test)[:, 1])\n",
        "        vector_auroc_validacion.append(auc_roc)\n",
        "        vector_auroc_train.append(roc_auc_score(kf_y_train, arbol.predict_proba(kf_X_train)[:, 1]))\n",
        "\n"
      ],
      "metadata": {
        "id": "z4bmfgMMyclj"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# accuracy\n",
        "print(\"Promedio de accuracys por fold:\", round(np.mean(vector_accuracy_validacion), 4))\n",
        "print(\"Accuracy global:\", round(accuracy_score(y_desarrollo, y_pred), 4))\n",
        "print()\n",
        "\n",
        "# AUPRC\n",
        "print(\"Promedio de AUPRC por fold:\", round(np.mean(vector_auprc_validacion), 4))\n",
        "print(\"AUPRC global:\", round(average_precision_score(y_desarrollo, y_pred_prob), 4))\n",
        "print()\n",
        "\n",
        "# AUROC\n",
        "print(\"Promedio de AUROC por fold:\", round(np.mean(vector_auroc_validacion), 4))\n",
        "print(\"AUROC global:\", round(roc_auc_score(y_desarrollo, y_pred_prob), 4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJqBomLR1JNm",
        "outputId": "487edae7-9400-46ca-f6ac-7d666c662e67"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Promedio de accuracys por fold: 0.7125\n",
            "Accuracy global: 0.7125\n",
            "\n",
            "Promedio de AUPRC por fold: 0.4487\n",
            "AUPRC global: 0.4369\n",
            "\n",
            "Promedio de AUROC por fold: 0.6822\n",
            "AUROC global: 0.6897\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Markdown, display\n",
        "\n",
        "tabla_md = \"\"\"\n",
        "| Métrica  | Promedio Fold | Global |\n",
        "|:--------:|:-------------:|:------:|\n",
        "| Accuracy |     0.7075    | 0.705  |\n",
        "| AUPRC    |     0.4359    | 0.4178 |\n",
        "| AUROC    |     0.6732    | 0.675  |\n",
        "\"\"\"\n",
        "\n",
        "display(Markdown(tabla_md))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "1WfEDUus3Nw2",
        "outputId": "87e4c3b4-497a-4edd-8598-6f2d64bba735"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\n| Métrica  | Promedio Fold | Global |\n|:--------:|:-------------:|:------:|\n| Accuracy |     0.7075    | 0.705  |\n| AUPRC    |     0.4359    | 0.4178 |\n| AUROC    |     0.6732    | 0.675  |\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A pesar de que obtuvimos un accuracy del 70%, este valor no es significativo debido al fuerte desbalance de clases del dataset. Ya de por si un clasificador trivial que predice siempre la clase negativa (mal pronóstico) ya alcanza esa predicción."
      ],
      "metadata": {
        "id": "IPVktS5r3jnd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Si miramos los resultados del AUPRC, considerando que nosotras tenemos clase positiva minoritaria, un modelo trivial tendria aproximadamente un AUPRC ≈ 0.29. El nuestro nos dio mejor que eso, asi que en este caso al menos superamos al azar."
      ],
      "metadata": {
        "id": "Ci_-7SNH4Cri"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Un modelo totalmente random tendria un AUROC de 0.5. El nuestro es un poco mejor, pero igualmente claramente necesita mejoras.\n"
      ],
      "metadata": {
        "id": "VLIqClcD4ZM6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En lo siguiente, completamos la tabla que se nos pide en el TP con los resultados obtenidos."
      ],
      "metadata": {
        "id": "nvjUJegA2oPF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creamos la tabla que se nos pide con los resultados obtenidos\n",
        "\n",
        "tabla_resultados = pd.DataFrame({\n",
        "    \"Permutación\": list(range(1, len(vector_accuracy_validacion)+1)),\n",
        "    \"Accuracy (training)\": [round(x,3) for x in vector_accuracy_train],\n",
        "    \"Accuracy (validación)\": [round(x,3) for x in vector_accuracy_validacion],\n",
        "    \"AUPRC (training)\": [round(x,3) for x in vector_auprc_train],\n",
        "    \"AUPRC (validación)\": [round(x,3) for x in vector_auprc_validacion],\n",
        "    \"AUC ROC (training)\": [round(x,3) for x in vector_auroc_train],\n",
        "    \"AUC ROC (validación)\": [round(x,3) for x in vector_auroc_validacion]\n",
        "})\n",
        "\n",
        "\n",
        "\n",
        "promedios = {\n",
        "    \"Permutación\": \"Promedio\",\n",
        "    \"Accuracy (training)\": round(np.mean(vector_accuracy_train), 3),\n",
        "    \"Accuracy (validación)\": round(np.mean(vector_accuracy_validacion), 3),\n",
        "    \"AUPRC (training)\": round(np.mean(vector_auprc_train), 3),\n",
        "    \"AUPRC (validación)\": round(np.mean(vector_auprc_validacion), 3),\n",
        "    \"AUC ROC (training)\": round(np.mean(vector_auroc_train), 3),\n",
        "    \"AUC ROC (validación)\": round(np.mean(vector_auroc_validacion), 3)\n",
        "}\n",
        "\n",
        "\n",
        "globales = {\n",
        "    \"Permutación\": \"Global\",\n",
        "    \"Accuracy (training)\": \"(NO)\",\n",
        "    \"Accuracy (validación)\": round(accuracy_score(y_desarrollo, y_pred), 3),\n",
        "    \"AUPRC (training)\": \"(NO)\",\n",
        "    \"AUPRC (validación)\": round(average_precision_score(y_desarrollo, y_pred_prob), 3),\n",
        "    \"AUC ROC (training)\": \"(NO)\",\n",
        "    \"AUC ROC (validación)\": round(roc_auc_score(y_desarrollo, y_pred_prob), 3)\n",
        "}\n",
        "\n",
        "tabla_resultados = pd.concat([\n",
        "    tabla_resultados,\n",
        "    pd.DataFrame([promedios]),\n",
        "    pd.DataFrame([globales])\n",
        "], ignore_index=True)\n",
        "\n",
        "display(HTML(tabla_resultados.to_html(index=False, justify='center')))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "LC_TPoC15T62",
        "outputId": "cf63c457-6f37-4d06-bea9-e650f4366e63"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: center;\">\n",
              "      <th>Permutación</th>\n",
              "      <th>Accuracy (training)</th>\n",
              "      <th>Accuracy (validación)</th>\n",
              "      <th>AUPRC (training)</th>\n",
              "      <th>AUPRC (validación)</th>\n",
              "      <th>AUC ROC (training)</th>\n",
              "      <th>AUC ROC (validación)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.856</td>\n",
              "      <td>0.650</td>\n",
              "      <td>0.72</td>\n",
              "      <td>0.406</td>\n",
              "      <td>0.874</td>\n",
              "      <td>0.616</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.853</td>\n",
              "      <td>0.750</td>\n",
              "      <td>0.713</td>\n",
              "      <td>0.516</td>\n",
              "      <td>0.842</td>\n",
              "      <td>0.686</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.853</td>\n",
              "      <td>0.725</td>\n",
              "      <td>0.704</td>\n",
              "      <td>0.444</td>\n",
              "      <td>0.829</td>\n",
              "      <td>0.693</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.847</td>\n",
              "      <td>0.688</td>\n",
              "      <td>0.749</td>\n",
              "      <td>0.363</td>\n",
              "      <td>0.855</td>\n",
              "      <td>0.637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.844</td>\n",
              "      <td>0.750</td>\n",
              "      <td>0.745</td>\n",
              "      <td>0.514</td>\n",
              "      <td>0.848</td>\n",
              "      <td>0.778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>Promedio</td>\n",
              "      <td>0.851</td>\n",
              "      <td>0.712</td>\n",
              "      <td>0.726</td>\n",
              "      <td>0.449</td>\n",
              "      <td>0.849</td>\n",
              "      <td>0.682</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>Global</td>\n",
              "      <td>(NO)</td>\n",
              "      <td>0.713</td>\n",
              "      <td>(NO)</td>\n",
              "      <td>0.437</td>\n",
              "      <td>(NO)</td>\n",
              "      <td>0.690</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La clase positiva es la clase minoritaria . La AUPRC (Area Under Precision-Recall Curve) es muy sensible al desbalance de clases. Y como tenemos muy pocos positivos tiene sentido que nos de un promedio global muy bajo en la validacion de aupcr  # anotar cositas de las diapos de clase sobre estos temas xd .\n",
        "Tambien tiene todo el sentido del mundo que eln los folds de entrenamiento nos de mucho mejor que en los sets de validacion ( trivial ) . Tanto roc como aupcr son sensibles a data set debalanceados como vimos en clase ."
      ],
      "metadata": {
        "id": "HFQQZkDlhIH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tiene sentido que el promedio de igual al global en este caso particular porque los folds tienen todos el mismo tamaño... desarrollar :)"
      ],
      "metadata": {
        "id": "fbEj0_z6tP_Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## como la clase mayoritaria son los negativos invertimos las etiquetas\n",
        "## pruebitas extras cambiando clases xd\n",
        "##  cambiando las etiquetas de las predicciones observamos que las metricas son mejroes\n",
        "\n",
        "\n",
        "# ---- Datos ----\n",
        "desarrollo_set = desarrollo_set.reset_index(drop=True)\n",
        "x_desarrollo = desarrollo_set.drop('target', axis=1)\n",
        "y_desarrollo = desarrollo_set['target']\n",
        "\n",
        "# Invertimos la clase: ahora la clase mayoritaria es la \"positiva\"\n",
        "y_desarrollo_invertida = 1 - y_desarrollo\n",
        "\n",
        "# ---- Stratified K-Fold ----\n",
        "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=22)\n",
        "\n",
        "# ---- Vectores de métricas ----\n",
        "vector_accuracy_train = []\n",
        "vector_accuracy_validacion = []\n",
        "vector_auprc_train = []\n",
        "vector_auprc_validacion = []\n",
        "vector_auroc_train = []\n",
        "vector_auroc_validacion = []\n",
        "\n",
        "# ---- Predicciones globales ----\n",
        "y_pred = np.empty(y_desarrollo.shape)\n",
        "y_pred.fill(np.nan)\n",
        "y_pred_prob = np.empty(y_desarrollo.shape)\n",
        "y_pred_prob.fill(np.nan)\n",
        "\n",
        "# ---- Entrenamiento y evaluación por fold ----\n",
        "for train_index, test_index in folds.split(x_desarrollo, y_desarrollo_invertida):\n",
        "    kf_X_train, kf_X_test = x_desarrollo.iloc[train_index], x_desarrollo.iloc[test_index]\n",
        "    kf_y_train, kf_y_test = y_desarrollo_invertida.iloc[train_index], y_desarrollo_invertida.iloc[test_index]\n",
        "\n",
        "    arbol = DecisionTreeClassifier(max_depth=3)\n",
        "    arbol.fit(kf_X_train, kf_y_train)\n",
        "\n",
        "    y_pred_fold = arbol.predict(kf_X_test)\n",
        "    y_pred_prob_fold = arbol.predict_proba(kf_X_test)[:, 1]\n",
        "\n",
        "    y_pred[test_index] = y_pred_fold\n",
        "    y_pred_prob[test_index] = y_pred_prob_fold\n",
        "\n",
        "    vector_accuracy_train.append(accuracy_score(kf_y_train, arbol.predict(kf_X_train)))\n",
        "    vector_accuracy_validacion.append(accuracy_score(kf_y_test, y_pred_fold))\n",
        "    vector_auprc_train.append(average_precision_score(kf_y_train, arbol.predict_proba(kf_X_train)[:, 1]))\n",
        "    vector_auprc_validacion.append(average_precision_score(kf_y_test, y_pred_prob_fold))\n",
        "    vector_auroc_train.append(roc_auc_score(kf_y_train, arbol.predict_proba(kf_X_train)[:, 1]))\n",
        "    vector_auroc_validacion.append(roc_auc_score(kf_y_test, y_pred_prob_fold))\n",
        "\n",
        "# ---- Cálculo de métricas globales ----\n",
        "accuracy_global = accuracy_score(y_desarrollo_invertida, y_pred)\n",
        "auprc_global = average_precision_score(y_desarrollo_invertida, y_pred_prob)\n",
        "auroc_global = roc_auc_score(y_desarrollo_invertida, y_pred_prob)\n",
        "\n",
        "# ---- Tabla de resultados ----\n",
        "tabla_resultados = pd.DataFrame({\n",
        "    \"Permutación\": list(range(1, 6)),\n",
        "    \"Accuracy (training)\": [round(x, 3) for x in vector_accuracy_train],\n",
        "    \"Accuracy (validación)\": [round(x, 3) for x in vector_accuracy_validacion],\n",
        "    \"AUPRC (training)\": [round(x, 3) for x in vector_auprc_train],\n",
        "    \"AUPRC (validación)\": [round(x, 3) for x in vector_auprc_validacion],\n",
        "    \"AUC ROC (training)\": [round(x, 3) for x in vector_auroc_train],\n",
        "    \"AUC ROC (validación)\": [round(x, 3) for x in vector_auroc_validacion]\n",
        "})\n",
        "\n",
        "# Fila de promedios\n",
        "promedios = {\n",
        "    \"Permutación\": \"Promedio\",\n",
        "    \"Accuracy (training)\": round(np.mean(vector_accuracy_train), 3),\n",
        "    \"Accuracy (validación)\": round(np.mean(vector_accuracy_validacion), 3),\n",
        "    \"AUPRC (training)\": round(np.mean(vector_auprc_train), 3),\n",
        "    \"AUPRC (validación)\": round(np.mean(vector_auprc_validacion), 3),\n",
        "    \"AUC ROC (training)\": round(np.mean(vector_auroc_train), 3),\n",
        "    \"AUC ROC (validación)\": round(np.mean(vector_auroc_validacion), 3)\n",
        "}\n",
        "\n",
        "# Fila de globales (correctamente usando etiquetas invertidas)\n",
        "globales = {\n",
        "    \"Permutación\": \"Global\",\n",
        "    \"Accuracy (training)\": \"(NO)\",\n",
        "    \"Accuracy (validación)\": round(accuracy_global, 3),\n",
        "    \"AUPRC (training)\": \"(NO)\",\n",
        "    \"AUPRC (validación)\": round(auprc_global, 3),\n",
        "    \"AUC ROC (training)\": \"(NO)\",\n",
        "    \"AUC ROC (validación)\": round(auroc_global, 3)\n",
        "}\n",
        "\n",
        "# Unir todo\n",
        "tabla_resultados = pd.concat([\n",
        "    tabla_resultados,\n",
        "    pd.DataFrame([promedios]),\n",
        "    pd.DataFrame([globales])\n",
        "], ignore_index=True)\n",
        "\n",
        "# Mostrar tabla centrada\n",
        "display(HTML(tabla_resultados.to_html(index=False, justify='center')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "m4jyLM_viVkb",
        "outputId": "676bbc32-9a0c-430e-dc89-48fc81f60d34"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: center;\">\n",
              "      <th>Permutación</th>\n",
              "      <th>Accuracy (training)</th>\n",
              "      <th>Accuracy (validación)</th>\n",
              "      <th>AUPRC (training)</th>\n",
              "      <th>AUPRC (validación)</th>\n",
              "      <th>AUC ROC (training)</th>\n",
              "      <th>AUC ROC (validación)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.856</td>\n",
              "      <td>0.625</td>\n",
              "      <td>0.917</td>\n",
              "      <td>0.752</td>\n",
              "      <td>0.874</td>\n",
              "      <td>0.573</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.853</td>\n",
              "      <td>0.750</td>\n",
              "      <td>0.891</td>\n",
              "      <td>0.796</td>\n",
              "      <td>0.842</td>\n",
              "      <td>0.686</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.853</td>\n",
              "      <td>0.725</td>\n",
              "      <td>0.881</td>\n",
              "      <td>0.817</td>\n",
              "      <td>0.829</td>\n",
              "      <td>0.693</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.847</td>\n",
              "      <td>0.688</td>\n",
              "      <td>0.899</td>\n",
              "      <td>0.802</td>\n",
              "      <td>0.855</td>\n",
              "      <td>0.637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.844</td>\n",
              "      <td>0.750</td>\n",
              "      <td>0.892</td>\n",
              "      <td>0.877</td>\n",
              "      <td>0.848</td>\n",
              "      <td>0.778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>Promedio</td>\n",
              "      <td>0.851</td>\n",
              "      <td>0.708</td>\n",
              "      <td>0.896</td>\n",
              "      <td>0.809</td>\n",
              "      <td>0.849</td>\n",
              "      <td>0.674</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>Global</td>\n",
              "      <td>(NO)</td>\n",
              "      <td>0.708</td>\n",
              "      <td>(NO)</td>\n",
              "      <td>0.805</td>\n",
              "      <td>(NO)</td>\n",
              "      <td>0.679</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.3) *Explorar las siguientes combinaciones de parámetros para árboles de decisión utilizando `ParameterGrid` de scikit learn. No está permitido utilizar `GridSearchCV` en este ejercicio.*"
      ],
      "metadata": {
        "id": "zS1y77haAA9C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Probamos disitnos parametros para nuestro arbol de decision\n",
        "\n",
        "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state = 22)\n",
        "\n",
        "alturas = [1,2,3,5,10,None]\n",
        "criterios = ['gini','entropy']\n",
        "accuracy_validacion = {}\n",
        "accuracy_train = {}\n",
        "\n",
        "for a in alturas:\n",
        "    for c in criterios:\n",
        "        vector_accuracy_validacion= []  # aca vamos a guardar los resultados de acurracy para cada fold de la validacion\n",
        "        vector_accuracy_train= [] # y del training\n",
        "\n",
        "        # generamos para cada fold una predicción\n",
        "        for train_index, test_index in folds.split(x_desarrollo,y_desarrollo):\n",
        "\n",
        "          #saco el fold que no uso para entrenar\n",
        "          kf_X_train, kf_X_test = x_desarrollo.iloc[train_index], x_desarrollo.iloc[test_index]\n",
        "          kf_y_train, kf_y_test = y_desarrollo.iloc[train_index], y_desarrollo.iloc[test_index]\n",
        "\n",
        "          # arbol fit con los datos de train\n",
        "          arbol = DecisionTreeClassifier(max_depth=a, criterion=c)\n",
        "          arbol.fit(kf_X_train, kf_y_train)\n",
        "\n",
        "          y_pred_val = arbol.predict(kf_X_test)\n",
        "          acc_val = accuracy_score(kf_y_test, y_pred_val)\n",
        "          vector_accuracy_validacion.append(acc_val)\n",
        "\n",
        "          y_pred_train = arbol.predict(kf_X_train)\n",
        "          acc_train = accuracy_score(kf_y_train, y_pred_train)\n",
        "          vector_accuracy_train.append(acc_train)\n",
        "\n",
        "        # Guardamos el promedio de accuracy de los folds\n",
        "        accuracy_validacion[(a, c)] = np.mean(vector_accuracy_validacion)\n",
        "        accuracy_train[(a, c)] = np.mean(vector_accuracy_train)\n",
        "\n",
        "print(accuracy_validacion)\n",
        "print(accuracy_train)\n",
        "# El mejor es gini con altura 5\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Lista para guardar filas de la tabla\n",
        "tabla_resultados = []\n",
        "\n",
        "# Recorremos las claves del diccionario (pares de (altura, criterio))\n",
        "for clave in accuracy_train.keys():\n",
        "    altura, criterio = clave\n",
        "    acc_train = accuracy_train[clave]\n",
        "    acc_val = accuracy_validacion[clave]\n",
        "\n",
        "    # Agregamos una fila a la tabla\n",
        "    tabla_resultados.append({\n",
        "        'Altura': altura,\n",
        "        'Criterio': criterio,\n",
        "        'Accuracy Train': acc_train,\n",
        "        'Accuracy Validación': acc_val\n",
        "    })\n",
        "\n",
        "# Creamos el DataFrame\n",
        "df_resultados = pd.DataFrame(tabla_resultados)\n",
        "\n",
        "# Mostramos la tabla ordenada por Altura y Criterio\n",
        "df_resultados = df_resultados.sort_values(by=['Altura', 'Criterio']).reset_index(drop=True)\n",
        "print(df_resultados)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2rSnCWDAGrT",
        "outputId": "1325057b-b527-4bc8-8f76-cac47abf9562"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{(1, 'gini'): np.float64(0.6775), (1, 'entropy'): np.float64(0.6775), (2, 'gini'): np.float64(0.7224999999999999), (2, 'entropy'): np.float64(0.735), (3, 'gini'): np.float64(0.71), (3, 'entropy'): np.float64(0.7150000000000001), (5, 'gini'): np.float64(0.71), (5, 'entropy'): np.float64(0.6799999999999999), (10, 'gini'): np.float64(0.6925000000000001), (10, 'entropy'): np.float64(0.6575), (None, 'gini'): np.float64(0.6925), (None, 'entropy'): np.float64(0.6475)}\n",
            "{(1, 'gini'): np.float64(0.7093750000000001), (1, 'entropy'): np.float64(0.7093750000000001), (2, 'gini'): np.float64(0.784375), (2, 'entropy'): np.float64(0.779375), (3, 'gini'): np.float64(0.850625), (3, 'entropy'): np.float64(0.825), (5, 'gini'): np.float64(0.945625), (5, 'entropy'): np.float64(0.93625), (10, 'gini'): np.float64(0.9956250000000001), (10, 'entropy'): np.float64(1.0), (None, 'gini'): np.float64(1.0), (None, 'entropy'): np.float64(1.0)}\n",
            "    Altura Criterio  Accuracy Train  Accuracy Validación\n",
            "0      1.0  entropy        0.709375               0.6775\n",
            "1      1.0     gini        0.709375               0.6775\n",
            "2      2.0  entropy        0.779375               0.7350\n",
            "3      2.0     gini        0.784375               0.7225\n",
            "4      3.0  entropy        0.825000               0.7150\n",
            "5      3.0     gini        0.850625               0.7100\n",
            "6      5.0  entropy        0.936250               0.6800\n",
            "7      5.0     gini        0.945625               0.7100\n",
            "8     10.0  entropy        1.000000               0.6575\n",
            "9     10.0     gini        0.995625               0.6925\n",
            "10     NaN  entropy        1.000000               0.6475\n",
            "11     NaN     gini        1.000000               0.6925\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Claramente a medida de que aumentamos el max_depth del arbol, vemos que la accuracy en los datos de train tiende a 100%, lo que tiene sentido, ya que calsifica bien todos estos datos (los memoriza). A su vez, para los datos de test. resulta peor. observamos overfitting."
      ],
      "metadata": {
        "id": "ZFuFzoZpFSJe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Estuvimos probando con otros valores y llegamos a la conclusion que la mejor altura es 2, ya que no solo, comparado a la performarnce en el test con otra alturas, es mejor, sino que tambien la diferencia con los datos de training es menor, osea que esta generalizando bastante bien, y no memoriza solo los datos de entrenamiento."
      ],
      "metadata": {
        "id": "08QWSDpuGclp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Ejercicio 3\n",
        "Importante: de acá en más sólamente utilizaremos el score promedio cuando hagamos K-fold cross-validation.\n",
        "\n",
        "Para el arbol de decision elegimos jugar con los siguientes hiperparametros:\n",
        "\n",
        "\n",
        "*   Max_depth (para regular el tamaño del arbol)\n",
        "*   class_weight (para tratar el desbalanceo de clases que tenemos)\n",
        "*   criterion\n",
        "*   min_samples_split (para definir cuantos hijos vamos a tener por rama como maximo)\n",
        "\n",
        "Por otro lado, para knn elegimos:\n",
        "* La cantidad de vecinos (k)\n",
        "* weights (darle mas peso a los que estan mas cercanos y menos a los mas alejados)\n",
        "* metrics (el tipo de distancia que usamos)\n",
        "\n",
        "Finalmente para SVM:\n",
        "* C (penalizacion por clasificacion equivocada)\n",
        "* kernel (hay distintos tipos)\n",
        "* class_weight (al ser desbalanceada nos conviene jugar con esto)\n"
      ],
      "metadata": {
        "id": "gaVJn8Bbj5g0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "aaZZ1gcglwDL"
      }
    }
  ]
}